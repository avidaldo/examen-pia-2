{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de detección de enfermedades de tiroides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del *pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class AgeOutlierImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to handle age outliers by imputing values over 150 \n",
    "    with the median age of the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=150):\n",
    "        self.threshold = threshold\n",
    "        self.median_age = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate median age excluding outliers\n",
    "        self.median_age = np.median(X[X <= self.threshold])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        mask = X_copy > self.threshold\n",
    "        X_copy[mask] = self.median_age\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSHLogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to handle TSH's right-skewed distribution \n",
    "    using log transformation with handling of zeros.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        # Add small constant before log transform to handle zeros\n",
    "        return np.log1p(X_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "standard_numeric = ['TT4', 'T4U', 'FTI', 'T3']\n",
    "\n",
    "# Special handling for TSH (right-skewed distribution)\n",
    "tsh_feature = ['TSH']\n",
    "\n",
    "\n",
    "# Binary categorical features\n",
    "binary_features = ['on_thyroxine', 'query_on_thyroxine', 'on_antithyroid_meds',\n",
    "                    'sick', 'pregnant', 'thyroid_surgery', 'I131_treatment',\n",
    "                    'query_hypothyroid', 'query_hyperthyroid', 'lithium',\n",
    "                    'goitre', 'tumor', 'hypopituitary', 'psych']\n",
    "\n",
    "# categorical categorical features\n",
    "categorical_features = ['sex', 'referral_source']\n",
    "\n",
    "# Create specialized pipelines\n",
    "age_pipeline = Pipeline([\n",
    "    ('outlier_handler', AgeOutlierImputer(threshold=150)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "standard_numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "tsh_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', TSHLogTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "])\n",
    "\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('age', age_pipeline, ['age']),\n",
    "        ('standard_numeric', standard_numeric_pipeline, standard_numeric),\n",
    "        ('tsh', tsh_pipeline, tsh_feature),\n",
    "        ('binary', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse_output=False), \n",
    "            binary_features),\n",
    "        ('categorical', categorical_pipeline, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El argumento `drop='if_binary'` de OneHotEncoder permite eliminar una de las columnas de salida cuando la variable categórica es binaria (crear una columna para f y otra para t es redundante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline_random_forest = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Pipeline* de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = \"./data/thyroidDF.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Simplify the target variable\n",
    "class_mapping = {\n",
    "    '-': 'negative',\n",
    "    'K': 'hyperthyroid', 'B': 'hyperthyroid', 'H|K': 'hyperthyroid',\n",
    "    'KJ': 'hyperthyroid', 'GI': 'hyperthyroid',\n",
    "    'G': 'hypothyroid', 'I': 'hypothyroid', 'F': 'hypothyroid', 'C|I': 'hypothyroid',\n",
    "    'E': 'negative', 'LJ': 'negative', 'D|R': 'negative',\n",
    "}\n",
    "\n",
    "df['target'] = df['target'].map(class_mapping)\n",
    "\n",
    "df = df.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_cols = [col for col in df.columns if col.endswith('_measured')]\n",
    "\n",
    "columns_to_drop = [\n",
    "    'patient_id',\n",
    "    *measured_cols,  # Unpack the list of measured columns\n",
    "    'TBG', # excessive missing values (96,6%)\n",
    "]\n",
    "\n",
    "X = df.drop(columns_to_drop + ['target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hyperthyroid', 'hypothyroid', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación y elección de modelos mediante *cross-validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos dos modelos con cross-validation, uno con los datos originales y otro con los datos escalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avidaldo/TRABAJO/IA/apuntes/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [12] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/avidaldo/TRABAJO/IA/apuntes/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [12] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.969093748152476\n",
      "SVM: 0.9410782701030904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_random_forest = cross_val_score(pipeline_random_forest, X_train, y_train, cv=stratified_cv, scoring='accuracy')\n",
    "scores_svm = cross_val_score(pipeline_svm, X_train, y_train, cv=stratified_cv, scoring='accuracy')\n",
    "\n",
    "print(f'Random Forest: {scores_random_forest.mean()}')\n",
    "print(f'SVM: {scores_svm.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos usado StratifiedKFold para mantener la proporción de clases en los *folds*.\n",
    "\n",
    "Hemos evaluado sobre sobre la *accuracy* (scoring='accuracy'). Sin embargo, tenemos unas clases un poco desbalanceadas, y además es más importante detectar los casos positivos (enfermos) que los negativos (sanos). Vamos por tanto a priorizar la sensibilidad (recall) en la evaluación de los modelos. Crearemos un evaluador personalizado que devuelva la *recall* media de las dos clases positivas (hypothyroid y hyperthyroid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avidaldo/TRABAJO/IA/apuntes/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [12] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/avidaldo/TRABAJO/IA/apuntes/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [12] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Disease Recall: 0.890\n",
      "SVM Disease Recall: 0.745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    # Get original class names from the LabelEncoder\n",
    "    all_classes = le.classes_\n",
    "    # Calculate recall for each class using original labels\n",
    "    recalls = recall_score(le.inverse_transform(y_true), \n",
    "                          le.inverse_transform(y_pred), \n",
    "                          labels=all_classes, \n",
    "                          average=None, \n",
    "                          zero_division=0)\n",
    "    # Get indices for disease classes\n",
    "    disease_indices = [np.where(all_classes == cls)[0][0] \n",
    "                      for cls in ['hyperthyroid', 'hypothyroid']]\n",
    "    return np.mean(recalls[disease_indices])\n",
    "\n",
    "disease_recall_scorer = make_scorer(custom_recall)\n",
    "\n",
    "scores_random_forest = cross_val_score(pipeline_random_forest, X_train, y_train, \n",
    "                                      cv=stratified_cv, scoring=disease_recall_scorer)\n",
    "scores_svm = cross_val_score(pipeline_svm, X_train, y_train, \n",
    "                            cv=stratified_cv, scoring=disease_recall_scorer)\n",
    "\n",
    "print(f'Random Forest Disease Recall: {scores_random_forest.mean():.3f}')\n",
    "print(f'SVM Disease Recall: {scores_svm.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el modelo Random Forest sigue siendo el mejor de los dos que hemos probado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación final en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_random_forest.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[32m      5\u001b[39m y_test_labels = le.inverse_transform(y_test)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(f'Matriz de Confusión')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        97\n",
      "           1       0.93      0.91      0.92       190\n",
      "           2       0.98      0.99      0.98      1355\n",
      "\n",
      "    accuracy                           0.97      1642\n",
      "   macro avg       0.95      0.93      0.94      1642\n",
      "weighted avg       0.97      0.97      0.97      1642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
